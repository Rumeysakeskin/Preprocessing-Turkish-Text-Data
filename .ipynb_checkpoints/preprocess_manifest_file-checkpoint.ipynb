{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b25ec42",
   "metadata": {},
   "source": [
    "• TAKE SAMPLES SHORTER THAN 20 SECONDS\n",
    "\n",
    "• LOWERCASE ALL TRANSCRIPTS\n",
    "\n",
    "• NORMALIZATION (NORMALIZE NUMBERS, PUNCTIATIONS, ABBREVIATIONS, SPECIAL CHARACTERS ETC.)\n",
    "\n",
    "• SHUFFLE MANIFEST FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9201905e",
   "metadata": {},
   "source": [
    "# Take samples shorter than 20 seconds and check filepaths are exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c92eabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "file = \"text_dataset.json\"\n",
    "file_out = \"new_text_dataset.jsonl\"\n",
    "\n",
    "total_duration = 0\n",
    "\n",
    "with open(file, \"r\", encoding=\"utf-8\") as fin:\n",
    "    with open(file_out, 'w', encoding=\"utf-8\") as fout:\n",
    "     \n",
    "        for line in fin:\n",
    "            original_file_json = json.loads(line)\n",
    "              \n",
    "            #CHANGE FILEPATH NAME\n",
    "            original_file_json[\"audio_filepath\"] = re.sub('/OLD/FILEPATH/', '/NEW/FILEPATH/', original_file_json[\"audio_filepath\"])   \n",
    "            \n",
    "            # TAKE SAMPLES SHORTER THAN 20 SECONDS AND HIGHER THAN 1 SECOND.\n",
    "            if original_file_json[\"duration\"] < 20 and original_file_json[\"duration\"] > 1:\n",
    "                json.dump(original_file_json, fout, ensure_ascii=False)\n",
    "                fout.write('\\n')\n",
    "\n",
    "                # SUM TOTAL TRAINING HOURS\n",
    "                total_duration += original_file_json[\"duration\"]\n",
    "                \n",
    "                # CHECK IF FILEPATH DIRECTORY IS EXISTS\n",
    "                isFile = os.path.isfile(original_file_json[\"audio_filepath\"]) \n",
    "                if isFile is False: # change False\n",
    "                    print(\"This file does not exist:\",original_file_json[\"audio_filepath\"])\n",
    "                                      \n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47cd7c9",
   "metadata": {},
   "source": [
    "# Total training data hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26bf6263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261.1068836111104"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_duration/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e852ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "_abbreviations = [(re.compile('\\\\b%s\\\\.' % x[0], re.IGNORECASE), x[1]) for x in [\n",
    "    ('adr', 'adres'),\n",
    "    ('agy', 'adı geçen yapıt'),\n",
    "    ('alb', 'albay'),\n",
    "    ('ank', 'ankara'),\n",
    "    ('ist', 'istanbul'),\n",
    "    ('apt', 'apartman'),\n",
    "    ('sok', 'sokak'),\n",
    "    ('cad', 'cadde'),\n",
    "    ('astsb', 'astsubay'),\n",
    "    ('atgm', 'asteğmen'),\n",
    "    ('bkz', 'bakınız'),\n",
    "    ('bknz', 'bakınız'),\n",
    "    ('bnb', 'binbaşı'),\n",
    "    ('bşk', 'başkanlığı'),\n",
    "    ('bştbp', 'baştabip'),\n",
    "    ('bul', 'bulvarı'),\n",
    "    ('bulv', 'bulvarı'),\n",
    "    ('cal', 'kalori'),\n",
    "    ('cm', 'santimetre'),\n",
    "    ('m', 'metre'),\n",
    "    ('gr', 'gram'),\n",
    "    ('çvş', 'çavuş'),\n",
    "    ('dl', 'desilitre'),\n",
    "    ('dm', 'desimetre'),\n",
    "    ('doç', 'doçent'),\n",
    "    ('dr', 'doktor'),\n",
    "    ('dz', 'deniz'),\n",
    "    ('kuv', 'kuvvetleri'),\n",
    "    ('yrb', 'yarbay'),\n",
    "    ('yy', 'yüzyıl'),\n",
    "    ('yard', 'yardımcı'),\n",
    "    ('müh', 'mühendis'),\n",
    "    ('ütğm', 'üsteğmen'),\n",
    "    ('uzm', 'uzman'),\n",
    "    ('müd', 'müdür'),\n",
    "    ('mm', 'milimetre'),    \n",
    "    ('mey', 'meydanı'),\n",
    "    ('mim', 'mimar'),    \n",
    "    ('mb', 'megabayt'),\n",
    "    ('gb', 'cigabayt'),\n",
    "    ('lt', 'litre'),\n",
    "    ('ltd', 'limited'),\n",
    "    ('kw', 'kilovat'),\n",
    "    ('km', 'kilometre'),\n",
    "    ('hrp', 'harp'),\n",
    "    ('gen', 'general'),\n",
    "    ('astsb', 'astsubay'),\n",
    "    ('atgm', 'asteğmen'),\n",
    "    ('ens', 'enstitüsü'),\n",
    "    ('ecz', 'eczanesi'),\n",
    "]]\n",
    "\n",
    "single_digit_dict = {\n",
    "    0: \"sıfır\",\n",
    "    1: \"bir\",\n",
    "    2: \"iki\",\n",
    "    3: \"üç\",\n",
    "    4: \"dört\",\n",
    "    5: \"beş\",\n",
    "    6: \"altı\",\n",
    "    7: \"yedi\",\n",
    "    8: \"sekiz\",\n",
    "    9: \"dokuz\"\n",
    "}\n",
    "\n",
    "double_digit_dict = {\n",
    "    1: \"on\",\n",
    "    2: \"yirmi\",\n",
    "    3: \"otuz\",\n",
    "    4: \"kırk\",\n",
    "    5: 'elli',\n",
    "    6: 'altmış',\n",
    "    7: 'yetmiş',\n",
    "    8: 'seksen',\n",
    "    9: 'doksan'\n",
    "}\n",
    "\n",
    "factorizations_list = [\n",
    "    [1e2, \"yüz\"],\n",
    "    [1e3, \"bin\"],\n",
    "    [1e6, \"milyon\"],\n",
    "    [1e9, \"milyar\"],\n",
    "    [1e12, \"trilyon\"],\n",
    "    [1e15, \"katrilyon\"],\n",
    "    [1e18, \"kentilyon\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260cd1d8",
   "metadata": {},
   "source": [
    "# Turkish text normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "67a4871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_url_re = re.compile(r'([a-zA-Z])\\.(com|gov|org)')\n",
    "def expand_urls(m):\n",
    "    if m.group(2) == \"com\":\n",
    "        group_2 = \"kom\"\n",
    "    else:\n",
    "        print(m.group(1))\n",
    "        print(m.group(2))\n",
    "        group_2 = m.group(2)\n",
    "    return f'{m.group(1)} nokta {group_2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_abbreviations(text):\n",
    "    for regex, replacement in _abbreviations:\n",
    "        text = re.sub(regex, replacement, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced2ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_punctuations_and_special_characters(text):\n",
    "    punc = '''!)\"(,':;«»?�‘’'…“”'''\n",
    "    \n",
    "    if \" gr \" in text:\n",
    "        text = text.replace(\" gr \", \" gram \")\n",
    "    if \" dk \" in text:\n",
    "        text = text.replace(\" dk \", \" dakika \")\n",
    "    if \" ml \" in text:\n",
    "        text = text.replace(\" ml \", \" mililitre \")\n",
    "       \n",
    "    for char in text:\n",
    "\n",
    "        if char == \"%\":\n",
    "            text = text.replace(char, \"yüzde \")\n",
    "        if char == \"½\":\n",
    "            text = text.replace(char, \"yarım\") # CHECHK AUDIO FILE\n",
    "        if char == \"¼\":\n",
    "            text = text.replace(char, \" çeyrek\")\n",
    "        if char == \"°\":\n",
    "            text = text.replace(char, \"derece\")\n",
    "        if char == \"+\":\n",
    "            text = text.replace(char, \" artı \")\n",
    "        if char == \"/\":\n",
    "            text = text.replace(char, \" bölü \")\n",
    "        if char == \"*\": \n",
    "            text = text.replace(char, \" çarpı \")\n",
    "      \n",
    "        \n",
    "        if char == \"&\":\n",
    "            text = text.replace(char, \"ve\") # CHECHK AUDIO FILE\n",
    "        if char == \"�\":\n",
    "            text = text.replace(char, \" \") # CHECHK AUDIO FILE\n",
    "\n",
    "        if char in punc:\n",
    "            text = text.replace(char, \"\")\n",
    "\n",
    "        if \"https\":\n",
    "            text = re.sub(\"https\", \"h t t p s\", text)   \n",
    "        if \"http\":\n",
    "            text = re.sub(\"http\", \"h t t p\", text)\n",
    "\n",
    "\n",
    "        if char == \"–\":\n",
    "            text = text.replace(char, \" \")\n",
    "        if char == \"-\":\n",
    "            text = text.replace(char, \" \")\n",
    "        \n",
    "\n",
    "        if char == \"i̇\" or char == \"î\":\n",
    "            text = text.replace(char, \"i\")\n",
    "        if char == \"û\":\n",
    "            text = text.replace(char, \"u\")\n",
    "        if char == \"â\":\n",
    "            text = text.replace(char, \"a\")\n",
    "        if char == \"é\":\n",
    "            text = text.replace(char, \"e\")\n",
    "        if char == \"\\xa0\":\n",
    "            text = text.replace(char, \" \") \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c766516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_integer_pronunciation(val: int) -> str:\n",
    "    \"\"\"\n",
    "    Converts given integer to its turkish text pronunciation\n",
    "    :param val: Integer number\n",
    "    :return: Turkish text representation of integer number\n",
    "    \"\"\"\n",
    "    if val < 10:\n",
    "        return single_digit_dict[val]\n",
    "\n",
    "    elif val < 100:\n",
    "        pronunciation = double_digit_dict[math.floor(val / 10)]\n",
    "        if val % 10 == 0:\n",
    "            return pronunciation\n",
    "        return double_digit_dict[math.floor(val / 10)] + \" \" + convert_integer_pronunciation(val % 10)\n",
    "\n",
    "    else:\n",
    "        for idx, (divider, factorization_name) in enumerate(factorizations_list):\n",
    "            next_factorization_divider = factorizations_list[idx + 1][0]\n",
    "\n",
    "            if val < next_factorization_divider:\n",
    "                first_part = math.floor(val / divider)\n",
    "                second_part = val % divider\n",
    "\n",
    "                if first_part != 1:\n",
    "                    pronunciation = convert_integer_pronunciation(first_part) + \" \"\n",
    "                else:\n",
    "                    pronunciation = \"\"\n",
    "\n",
    "                pronunciation = pronunciation + factorization_name\n",
    "\n",
    "                if second_part != 0:\n",
    "                    pronunciation += \" \" + convert_integer_pronunciation(second_part)\n",
    "\n",
    "                return pronunciation\n",
    "            \n",
    "def find_and_normalize_number(text: str) -> str:\n",
    "\n",
    "    result = re.search(\"[0-9]+\", text)\n",
    "    found = result is not None\n",
    "\n",
    "    if found:\n",
    "        value = int(result.group())\n",
    "        pronunciation = convert_integer_pronunciation(value)\n",
    "        text = list(text)\n",
    "        text[result.start():result.end()] = pronunciation\n",
    "        text = \"\".join(text)\n",
    "\n",
    "    return found, text\n",
    "\n",
    "def normalize_numbers(text: str) -> str:\n",
    "    number_normalized, new_text = find_and_normalize_number(text)\n",
    "    while number_normalized:\n",
    "        number_normalized, new_text = find_and_normalize_number(new_text)\n",
    "\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "34916dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 119370/119370 [00:47<00:00, 2528.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_vocab: {':', '‘', 'ö', 'j', '̇', \"'\", '?', '�', '–', 'h', 'ı', '”', 'd', 'g', 's', '%', 't', 'x', ',', 'p', 'm', '½', '»', ' ', '’', 'ü', 'f', 'ğ', 'a', '…', 'v', 'r', '\"', 'w', 'l', 'i', 'z', 'c', 'é', ';', '&', '«', '-', 'b', 'â', 'q', 'o', '!', '“', 'e', 'n', 'ş', '.', 'k', 'ç', 'y', 'u'}\n",
      "cleaned_vocab: {'ö', 'j', '̇', '–', 'h', 'ı', 'd', 'g', 's', 't', 'x', 'p', 'm', ' ', 'ü', 'f', 'ğ', 'a', 'v', 'r', 'w', 'l', 'i', 'z', 'c', 'b', 'q', 'o', 'e', 'n', 'ş', '.', 'k', 'ç', 'y', 'u'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = file_out\n",
    "file_normalized = \"normalized_manifest_file.jsonl\"\n",
    "\n",
    "original_vocab = set()\n",
    "cleaned_vocab = set()\n",
    "\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "    with open(file_normalized, 'w', encoding=\"utf-8\") as fp:\n",
    "    \n",
    "        for line in tqdm(liste):\n",
    "            original_file_json = json.loads(line)\n",
    "                \n",
    "            original_vocab.update(list(original_file_json[\"text\"]))\n",
    "            \n",
    "            text = original_file_json[\"text\"]\n",
    "            \n",
    "            text = text.lower()\n",
    "            text = re.sub(_url_re, expand_urls, text)\n",
    "            text = normalize_numbers(text)\n",
    "            text = normalize_abbreviations(text)\n",
    "            new_text = normalize_punctuations_and_special_characters(text)\n",
    "\n",
    "            cleaned_vocab.update(list(new_text))\n",
    "            \n",
    "            original_file_json[\"text\"] = new_text\n",
    "            json.dump(original_file_json, fp, ensure_ascii=False)\n",
    "            fp.write('\\n')\n",
    "                    \n",
    "print(\"original_vocab:\", original_vocab) \n",
    "print(\"cleaned_vocab:\", cleaned_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02dde46",
   "metadata": {},
   "source": [
    "# Shuffle the manifest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ccc49ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119370"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste = []\n",
    "\n",
    "cleaned_file_path = file_normalized\n",
    "\n",
    "with open(cleaned_file_path, 'r', encoding=\"utf-8\") as f:  \n",
    "    for line in f:\n",
    "        liste.append(line) \n",
    "        \n",
    "len(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b58b49be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifest file ready for training!\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(liste)\n",
    "preprocessed_file_path = \"preprocessed_manifest_file.jsonl\"\n",
    "with open(preprocessed_file_path, 'w', encoding=\"utf-8\") as f:  \n",
    "    for line in liste:\n",
    "        f.write(line)\n",
    "print(\"Manifest file ready for training!\")"
   ]
  }
 ],
 "metadata": {
  "direction": "ltr",
  "kernelspec": {
   "display_name": "uluc_nemo",
   "language": "python",
   "name": "uluc_nemo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
